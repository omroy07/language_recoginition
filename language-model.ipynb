{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee17a3cd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-20T09:34:14.049365Z",
     "iopub.status.busy": "2024-12-20T09:34:14.048949Z",
     "iopub.status.idle": "2024-12-20T09:34:20.884212Z",
     "shell.execute_reply": "2024-12-20T09:34:20.883336Z"
    },
    "papermill": {
     "duration": 6.844031,
     "end_time": "2024-12-20T09:34:20.886649",
     "exception": false,
     "start_time": "2024-12-20T09:34:14.042618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(r'D:\\MLPROJECTS\\Language_Recognition\\dataset.csv'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1b759",
   "metadata": {
    "papermill": {
     "duration": 0.003994,
     "end_time": "2024-12-20T09:34:20.895193",
     "exception": false,
     "start_time": "2024-12-20T09:34:20.891199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So i will be using spaCy model for the purpose...\n",
    "steps:\n",
    "1. load the universal spaCy model\n",
    "2. prepare the data\n",
    "3. preprocess the data (by cleaning it i.e. removing the multiple spaces if present)\n",
    "4. training data processing (splitting the data)\n",
    "5. Then i will be doing the vectorization\n",
    "6. After this i will decide what i want to do, since there are multiple classifiers that i can use after Vectorization\n",
    "Maybe i will follow something like the thing that i did in my sentiment analysis project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b4e7922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:34:57.635926Z",
     "iopub.status.busy": "2024-12-20T09:34:57.634693Z",
     "iopub.status.idle": "2024-12-20T09:35:00.396113Z",
     "shell.execute_reply": "2024-12-20T09:35:00.394747Z"
    },
    "papermill": {
     "duration": 2.772169,
     "end_time": "2024-12-20T09:35:00.398697",
     "exception": false,
     "start_time": "2024-12-20T09:34:57.626528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"xx_ent_wiki_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dff0bc3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:00.414923Z",
     "iopub.status.busy": "2024-12-20T09:35:00.414123Z",
     "iopub.status.idle": "2024-12-20T09:35:00.502069Z",
     "shell.execute_reply": "2024-12-20T09:35:00.500824Z"
    },
    "papermill": {
     "duration": 0.097867,
     "end_time": "2024-12-20T09:35:00.504404",
     "exception": false,
     "start_time": "2024-12-20T09:35:00.406537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  language\n",
      "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4  de spons behoort tot het geslacht haliclona en...     Dutch\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\MLPROJECTS\\Language_Recognition\\dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8da5c",
   "metadata": {
    "papermill": {
     "duration": 0.006364,
     "end_time": "2024-12-20T09:35:00.517299",
     "exception": false,
     "start_time": "2024-12-20T09:35:00.510935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Lets begin our preprocessing step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "956320f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:00.532021Z",
     "iopub.status.busy": "2024-12-20T09:35:00.531642Z",
     "iopub.status.idle": "2024-12-20T09:35:33.963094Z",
     "shell.execute_reply": "2024-12-20T09:35:33.962048Z"
    },
    "papermill": {
     "duration": 33.441796,
     "end_time": "2024-12-20T09:35:33.965638",
     "exception": false,
     "start_time": "2024-12-20T09:35:00.523842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "def yele(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['Text'] = df['Text'].apply(yele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afd70378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:33.980875Z",
     "iopub.status.busy": "2024-12-20T09:35:33.980488Z",
     "iopub.status.idle": "2024-12-20T09:35:33.985694Z",
     "shell.execute_reply": "2024-12-20T09:35:33.984671Z"
    },
    "papermill": {
     "duration": 0.015322,
     "end_time": "2024-12-20T09:35:33.987828",
     "exception": false,
     "start_time": "2024-12-20T09:35:33.972506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# print(df.iloc[10334][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492b0c8",
   "metadata": {
    "papermill": {
     "duration": 0.006292,
     "end_time": "2024-12-20T09:35:34.000759",
     "exception": false,
     "start_time": "2024-12-20T09:35:33.994467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Lets begin our training data processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe3ece9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:34.015896Z",
     "iopub.status.busy": "2024-12-20T09:35:34.015039Z",
     "iopub.status.idle": "2024-12-20T09:35:34.027705Z",
     "shell.execute_reply": "2024-12-20T09:35:34.026299Z"
    },
    "papermill": {
     "duration": 0.022772,
     "end_time": "2024-12-20T09:35:34.030023",
     "exception": false,
     "start_time": "2024-12-20T09:35:34.007251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19800\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "X = df['Text']\n",
    "y = df['language']\n",
    "\n",
    "X_t, X_test, y_t, y_test = train_test_split(X,y,test_size = 0.1, random_state = 1)\n",
    "\n",
    "print(len(X_t))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895531a",
   "metadata": {
    "papermill": {
     "duration": 0.006268,
     "end_time": "2024-12-20T09:35:34.042996",
     "exception": false,
     "start_time": "2024-12-20T09:35:34.036728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the vectorization process begins from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22c92f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:34.057657Z",
     "iopub.status.busy": "2024-12-20T09:35:34.057185Z",
     "iopub.status.idle": "2024-12-20T09:35:34.396735Z",
     "shell.execute_reply": "2024-12-20T09:35:34.395642Z"
    },
    "papermill": {
     "duration": 0.349907,
     "end_time": "2024-12-20T09:35:34.399454",
     "exception": false,
     "start_time": "2024-12-20T09:35:34.049547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "y_t_vec = enc.fit_transform(y_t)\n",
    "y_test_vec = enc.transform(y_test)\n",
    "X_t_vec = vect.fit_transform(X_t)\n",
    "X_test_vec = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95091eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:34.415132Z",
     "iopub.status.busy": "2024-12-20T09:35:34.414226Z",
     "iopub.status.idle": "2024-12-20T09:35:34.761521Z",
     "shell.execute_reply": "2024-12-20T09:35:34.760348Z"
    },
    "papermill": {
     "duration": 0.357552,
     "end_time": "2024-12-20T09:35:34.763703",
     "exception": false,
     "start_time": "2024-12-20T09:35:34.406151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF training data shape: (19800, 5000)\n",
      "TF-IDF testing data shape: (2200, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_t_tf = tfidf.fit_transform(X_t)\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF training data shape: {X_t_tf.shape}\")\n",
    "print(f\"TF-IDF testing data shape: {X_test_tf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e8c504a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:34.779482Z",
     "iopub.status.busy": "2024-12-20T09:35:34.779081Z",
     "iopub.status.idle": "2024-12-20T09:35:34.796067Z",
     "shell.execute_reply": "2024-12-20T09:35:34.794757Z"
    },
    "papermill": {
     "duration": 0.027988,
     "end_time": "2024-12-20T09:35:34.798483",
     "exception": false,
     "start_time": "2024-12-20T09:35:34.770495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 91.41%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_t_tf, y_t_vec)\n",
    "predi = clf_nb.predict(X_test_tf)\n",
    "accuracy_logreg = accuracy_score(y_test_vec, predi)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3363281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:34.813791Z",
     "iopub.status.busy": "2024-12-20T09:35:34.813421Z",
     "iopub.status.idle": "2024-12-20T09:35:39.834687Z",
     "shell.execute_reply": "2024-12-20T09:35:39.830813Z"
    },
    "papermill": {
     "duration": 5.0352,
     "end_time": "2024-12-20T09:35:39.840582",
     "exception": false,
     "start_time": "2024-12-20T09:35:34.805382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 93.68%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logi = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "logi.fit(X_t_tf, y_t_vec)\n",
    "\n",
    "predi = logi.predict(X_test_tf)\n",
    "\n",
    "accuracy_logreg = accuracy_score(y_test_vec, predi)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff30c1ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:39.901737Z",
     "iopub.status.busy": "2024-12-20T09:35:39.901181Z",
     "iopub.status.idle": "2024-12-20T09:35:39.922536Z",
     "shell.execute_reply": "2024-12-20T09:35:39.921471Z"
    },
    "papermill": {
     "duration": 0.05369,
     "end_time": "2024-12-20T09:35:39.929415",
     "exception": false,
     "start_time": "2024-12-20T09:35:39.875725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japanese' 'Chinese' 'Chinese']\n"
     ]
    }
   ],
   "source": [
    "yele = ['Hello my name is this', 'salut, je mappelle ainsi' , 'привет, меня зовут это', ]\n",
    "yele_tf = tfidf.transform(yele)\n",
    "\n",
    "answer = logi.predict(yele_tf)\n",
    "ans = enc.inverse_transform(answer)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a37dac3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:39.955228Z",
     "iopub.status.busy": "2024-12-20T09:35:39.954852Z",
     "iopub.status.idle": "2024-12-20T09:35:43.376492Z",
     "shell.execute_reply": "2024-12-20T09:35:43.375369Z"
    },
    "papermill": {
     "duration": 3.43202,
     "end_time": "2024-12-20T09:35:43.378706",
     "exception": false,
     "start_time": "2024-12-20T09:35:39.946686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiten\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 93.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(kernel='linear', max_iter=1000)\n",
    "clf_svm.fit(X_t_tf, y_t_vec)\n",
    "predi = clf_svm.predict(X_test_tf)\n",
    "accuracy_logreg = accuracy_score(y_test_vec, predi)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1750694e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:35:43.394336Z",
     "iopub.status.busy": "2024-12-20T09:35:43.393905Z",
     "iopub.status.idle": "2024-12-20T09:35:43.401421Z",
     "shell.execute_reply": "2024-12-20T09:35:43.400341Z"
    },
    "papermill": {
     "duration": 0.018049,
     "end_time": "2024-12-20T09:35:43.403763",
     "exception": false,
     "start_time": "2024-12-20T09:35:43.385714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_path = r'D:\\MLPROJECTS\\Language_Recognition\\language_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(clf_svm, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "317eabfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, vectorizer, and encoder saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load multilingual spaCy model\n",
    "nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")  # Make sure it's in the same folder or adjust path\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    doc = nlp(str(text))\n",
    "    return \" \".join([token.text for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df['Text']\n",
    "y = df['language']\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Train model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Save model, vectorizer, and encoder\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "print(\"Model, vectorizer, and encoder saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1150837,
     "sourceId": 1929264,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.912421,
   "end_time": "2024-12-20T09:35:44.849963",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-20T09:34:10.937542",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
